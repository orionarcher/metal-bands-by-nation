{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJZhgj0Spc91"
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvk8A1W4phc4"
   },
   "source": [
    "# Importing Data\n",
    "# start with importing messy data set but then use metal stuff for the rest of the teaching example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TM3TlJfmkxkc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL locations of data\n",
    "master_death_metal_bands = \"https://raw.githubusercontent.com/orioncohen/metal-bands-by-nation/main/bands.csv\"\n",
    "master_metal_bands = \"https://raw.githubusercontent.com/orioncohen/metal-bands-by-nation/main/metal_bands_2017.csv\"\n",
    "master_world_pop = \"https://raw.githubusercontent.com/orioncohen/metal-bands-by-nation/main/world_population_1960_2015.csv\"\n",
    "\n",
    "# Grab the metal bands data\n",
    "req = requests.get(master_death_metal_bands)\n",
    "death_metal_bands_data = req.text\n",
    "\n",
    "# Grab the metal bands data\n",
    "req = requests.get(master_metal_bands)\n",
    "metal_bands_data = req.text\n",
    "\n",
    "# Grab the world population data\n",
    "req = requests.get(master_world_pop)\n",
    "world_pop_data = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Realistic Depiction of Getting Data into Python\n",
    "\n",
    "Exciting! We have some fresh new cyclic voltammetry data to analyze. Fortuitously, `pandas` has a function called `read_csv` design for loading tabular data. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb2 in position 1135: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_133233/4091226151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cyclic_voltammetry_output.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb2 in position 1135: invalid start byte"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"cyclic_voltammetry_output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh! Our loading failed terribly! Let's take a look at our file to see what might be amiss.\n",
    "\n",
    "It looks like our data doesn't actually start until line 81, as indicated by \"Nb header lines: 81\" on the second line. May have been wise to look at our file first, but eh, lesson learned.\n",
    "\n",
    "Ok, now we need to turn to the [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for help. Like a good programmer, I'll google it to find the key word arguments that we can use to modify `read_csv`.\n",
    "\n",
    "... google \"how to skip lines in pd read csv\" ...\n",
    "\n",
    "Aha! The keyword `skiprows` appears to be what we are looking for. It's description states \"Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file.\" There are 81 lines, but the line numbers to skip are 0-indexed, which means that we will want `skiprows` to have a value of 80. Let's give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode\\tox/red\\terror\\tcontrol changes\\tNs changes\\tcounter inc.\\tNs\\ttime/s\\tcontrol/V/mA\\tEwe/V\\tdq/mA.h\\tEce/V\\tP/W\\t&lt;I&gt;/mA\\tEwe-Ece/V\\tx\\t(Q-Qo)/mA.h\\tCapacity/mA.h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3\\t1\\t0\\t0\\t0\\t0\\t0\\t0.0002\\t0\\t3.13411832\\t0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3\\t1\\t0\\t0\\t0\\t0\\t0\\t60.0002\\t0\\t3.13436651\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\t1\\t0\\t0\\t0\\t0\\t0\\t120.0002\\t0\\t3.13472915\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3\\t1\\t0\\t0\\t0\\t0\\t0\\t180.0002\\t0\\t3.13482451\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3\\t1\\t0\\t0\\t0\\t0\\t0\\t240.0002\\t0\\t3.13497734\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23215</th>\n",
       "      <td>1\\t0\\t0\\t0\\t0\\t0\\t1\\t417662.4821\\t-0.01425\\t2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23216</th>\n",
       "      <td>1\\t0\\t0\\t0\\t0\\t0\\t1\\t417699.5241\\t-0.01425\\t2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>1\\t0\\t0\\t0\\t0\\t0\\t1\\t417733.6881\\t-0.01425\\t2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>1\\t0\\t0\\t0\\t0\\t0\\t1\\t417733.6951\\t-0.01425\\t2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>1\\t0\\t0\\t0\\t0\\t0\\t1\\t417734.9321\\t-0.01425\\t2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mode\\tox/red\\terror\\tcontrol changes\\tNs changes\\tcounter inc.\\tNs\\ttime/s\\tcontrol/V/mA\\tEwe/V\\tdq/mA.h\\tEce/V\\tP/W\\t<I>/mA\\tEwe-Ece/V\\tx\\t(Q-Qo)/mA.h\\tCapacity/mA.h\n",
       "0      3\\t1\\t0\\t0\\t0\\t0\\t0\\t0.0002\\t0\\t3.13411832\\t0\\...                                                                                                                    \n",
       "1      3\\t1\\t0\\t0\\t0\\t0\\t0\\t60.0002\\t0\\t3.13436651\\t0...                                                                                                                    \n",
       "2      3\\t1\\t0\\t0\\t0\\t0\\t0\\t120.0002\\t0\\t3.13472915\\t...                                                                                                                    \n",
       "3      3\\t1\\t0\\t0\\t0\\t0\\t0\\t180.0002\\t0\\t3.13482451\\t...                                                                                                                    \n",
       "4      3\\t1\\t0\\t0\\t0\\t0\\t0\\t240.0002\\t0\\t3.13497734\\t...                                                                                                                    \n",
       "...                                                  ...                                                                                                                    \n",
       "23215  1\\t0\\t0\\t0\\t0\\t0\\t1\\t417662.4821\\t-0.01425\\t2....                                                                                                                    \n",
       "23216  1\\t0\\t0\\t0\\t0\\t0\\t1\\t417699.5241\\t-0.01425\\t2....                                                                                                                    \n",
       "23217  1\\t0\\t0\\t0\\t0\\t0\\t1\\t417733.6881\\t-0.01425\\t2....                                                                                                                    \n",
       "23218  1\\t0\\t0\\t0\\t0\\t0\\t1\\t417733.6951\\t-0.01425\\t2....                                                                                                                    \n",
       "23219  1\\t0\\t0\\t0\\t0\\t0\\t1\\t417734.9321\\t-0.01425\\t2....                                                                                                                    \n",
       "\n",
       "[23220 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"cyclic_voltammetry_output.txt\", skiprows=80, encoding='mac_roman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns aren't separated and we have `\\t` characters all over the place, but still, progress! The `\\t` characters are the separators in our data file, meaning our file is `tab`-seperated. Even though `csv` stands for Comma Seperated Values, other seperator characters are also common.\n",
    "\n",
    "... google \"how to specify separator in pd\" ...\n",
    "\n",
    "Looks like we can specify the type of separator by including the `sep` keyword. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>ox/red</th>\n",
       "      <th>error</th>\n",
       "      <th>control changes</th>\n",
       "      <th>Ns changes</th>\n",
       "      <th>counter inc.</th>\n",
       "      <th>Ns</th>\n",
       "      <th>time/s</th>\n",
       "      <th>control/V/mA</th>\n",
       "      <th>Ewe/V</th>\n",
       "      <th>dq/mA.h</th>\n",
       "      <th>Ece/V</th>\n",
       "      <th>P/W</th>\n",
       "      <th>&lt;I&gt;/mA</th>\n",
       "      <th>Ewe-Ece/V</th>\n",
       "      <th>x</th>\n",
       "      <th>(Q-Qo)/mA.h</th>\n",
       "      <th>Capacity/mA.h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.134118</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.136817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.134367</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.136970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.134729</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.137256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.134825</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.137352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.134977</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.137333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>417662.4821</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>2.021435</td>\n",
       "      <td>-1.447666e-04</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.014246</td>\n",
       "      <td>2.004511</td>\n",
       "      <td>1.917172</td>\n",
       "      <td>-0.328737</td>\n",
       "      <td>0.135839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23216</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>417699.5241</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>2.020919</td>\n",
       "      <td>-1.465844e-04</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.014246</td>\n",
       "      <td>2.004148</td>\n",
       "      <td>1.918027</td>\n",
       "      <td>-0.328884</td>\n",
       "      <td>0.135986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>417733.6881</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>2.020404</td>\n",
       "      <td>-1.351955e-04</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.014246</td>\n",
       "      <td>2.003442</td>\n",
       "      <td>1.918815</td>\n",
       "      <td>-0.329019</td>\n",
       "      <td>0.136121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>417733.6951</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>2.020938</td>\n",
       "      <td>-2.770032e-08</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.014246</td>\n",
       "      <td>2.004148</td>\n",
       "      <td>1.918815</td>\n",
       "      <td>-0.329019</td>\n",
       "      <td>0.136121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>417734.9321</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>2.020423</td>\n",
       "      <td>-4.895096e-06</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.014246</td>\n",
       "      <td>2.003576</td>\n",
       "      <td>1.918844</td>\n",
       "      <td>-0.329024</td>\n",
       "      <td>0.136126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23220 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mode  ox/red  error  control changes  Ns changes  counter inc.  Ns  \\\n",
       "0         3       1      0                0           0             0   0   \n",
       "1         3       1      0                0           0             0   0   \n",
       "2         3       1      0                0           0             0   0   \n",
       "3         3       1      0                0           0             0   0   \n",
       "4         3       1      0                0           0             0   0   \n",
       "...     ...     ...    ...              ...         ...           ...  ..   \n",
       "23215     1       0      0                0           0             0   1   \n",
       "23216     1       0      0                0           0             0   1   \n",
       "23217     1       0      0                0           0             0   1   \n",
       "23218     1       0      0                0           0             0   1   \n",
       "23219     1       0      0                0           0             0   1   \n",
       "\n",
       "            time/s  control/V/mA     Ewe/V       dq/mA.h     Ece/V       P/W  \\\n",
       "0           0.0002       0.00000  3.134118  0.000000e+00 -0.002699  0.000000   \n",
       "1          60.0002       0.00000  3.134367  0.000000e+00 -0.002604  0.000000   \n",
       "2         120.0002       0.00000  3.134729  0.000000e+00 -0.002527  0.000000   \n",
       "3         180.0002       0.00000  3.134825  0.000000e+00 -0.002527  0.000000   \n",
       "4         240.0002       0.00000  3.134977  0.000000e+00 -0.002355  0.000000   \n",
       "...            ...           ...       ...           ...       ...       ...   \n",
       "23215  417662.4821      -0.01425  2.021435 -1.447666e-04  0.016924  0.000029   \n",
       "23216  417699.5241      -0.01425  2.020919 -1.465844e-04  0.016771  0.000029   \n",
       "23217  417733.6881      -0.01425  2.020404 -1.351955e-04  0.016962  0.000029   \n",
       "23218  417733.6951      -0.01425  2.020938 -2.770032e-08  0.016790  0.000029   \n",
       "23219  417734.9321      -0.01425  2.020423 -4.895096e-06  0.016847  0.000029   \n",
       "\n",
       "         <I>/mA  Ewe-Ece/V         x  (Q-Qo)/mA.h  Capacity/mA.h  \n",
       "0      0.000000   3.136817  0.000000     0.000000       0.000000  \n",
       "1      0.000000   3.136970  0.000000     0.000000       0.000000  \n",
       "2      0.000000   3.137256  0.000000     0.000000       0.000000  \n",
       "3      0.000000   3.137352  0.000000     0.000000       0.000000  \n",
       "4      0.000000   3.137333  0.000000     0.000000       0.000000  \n",
       "...         ...        ...       ...          ...            ...  \n",
       "23215 -0.014246   2.004511  1.917172    -0.328737       0.135839  \n",
       "23216 -0.014246   2.004148  1.918027    -0.328884       0.135986  \n",
       "23217 -0.014246   2.003442  1.918815    -0.329019       0.136121  \n",
       "23218 -0.014246   2.004148  1.918815    -0.329019       0.136121  \n",
       "23219 -0.014246   2.003576  1.918844    -0.329024       0.136126  \n",
       "\n",
       "[23220 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"cyclic_voltammetry_output.txt\", skiprows=80, sep='\\t', encoding='mac_roman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Yay! We've successfully imported our DataFrame. Sometimes it just takes a little tinkering. We are going to move on to a nicer dataset for the rest of the workshop but hopefully this has given you a realistic view of how to troubleshoot your imports!\n",
    "\n",
    "In the next cell, we will import our data directly from a file hosted on GitHub. This is no harder than loading a `.csv` file on our local computer. We'll use this sick death metal data going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "STJjQ_h2mLbQ"
   },
   "outputs": [],
   "source": [
    "# Make a data frame\n",
    "metal_bands_df = pd.read_csv(\"https://raw.githubusercontent.com/orioncohen/metal-bands-by-nation/main/metal_bands_2017.csv\")\n",
    "world_pop_df = pd.read_csv(\"world_population_1960_2015.csv\")\n",
    "bands_df = pd.read_csv(\"bands.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9FouXLapZdK"
   },
   "source": [
    "# Creating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data to see what we're working with! We can look at just the first set of lines with the `head()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>band_name</th>\n",
       "      <th>fans</th>\n",
       "      <th>formed</th>\n",
       "      <th>origin</th>\n",
       "      <th>split</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iron Maiden</td>\n",
       "      <td>4195</td>\n",
       "      <td>1975</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>-</td>\n",
       "      <td>New wave of british heavy,Heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Opeth</td>\n",
       "      <td>4147</td>\n",
       "      <td>1990</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>1990</td>\n",
       "      <td>Extreme progressive,Progressive rock,Progressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>3712</td>\n",
       "      <td>1981</td>\n",
       "      <td>USA</td>\n",
       "      <td>-</td>\n",
       "      <td>Heavy,Bay area thrash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Megadeth</td>\n",
       "      <td>3105</td>\n",
       "      <td>1983</td>\n",
       "      <td>USA</td>\n",
       "      <td>1983</td>\n",
       "      <td>Thrash,Heavy,Hard rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Amon Amarth</td>\n",
       "      <td>3054</td>\n",
       "      <td>1988</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>-</td>\n",
       "      <td>Melodic death</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    band_name  fans formed          origin split  \\\n",
       "0           0             0  Iron Maiden  4195   1975  United Kingdom     -   \n",
       "1           1             1        Opeth  4147   1990          Sweden  1990   \n",
       "2           2             2    Metallica  3712   1981             USA     -   \n",
       "3           3             3     Megadeth  3105   1983             USA  1983   \n",
       "4           4             4  Amon Amarth  3054   1988          Sweden     -   \n",
       "\n",
       "                                              style  \n",
       "0                   New wave of british heavy,Heavy  \n",
       "1  Extreme progressive,Progressive rock,Progressive  \n",
       "2                             Heavy,Bay area thrash  \n",
       "3                            Thrash,Heavy,Hard rock  \n",
       "4                                     Melodic death  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metal_bands_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    5000 non-null   int64 \n",
      " 1   Unnamed: 0.1  5000 non-null   int64 \n",
      " 2   band_name     5000 non-null   object\n",
      " 3   fans          5000 non-null   int64 \n",
      " 4   formed        5000 non-null   object\n",
      " 5   origin        4992 non-null   object\n",
      " 6   split         5000 non-null   object\n",
      " 7   style         5000 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "metal_bands_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we know a bunch of information about each metal band! We have their `'name'`, their `'country'`, their `'genre'`...even the years that they were `'active'`! These are the columns of this data frame. Note that the `'id'` is different from the row number: `'id'` is a column in the data frame, so if we sorted the data differently, those would be reordered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check out our other data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>54208.0</td>\n",
       "      <td>55435.0</td>\n",
       "      <td>56226.0</td>\n",
       "      <td>56697.0</td>\n",
       "      <td>57029.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>57712.0</td>\n",
       "      <td>58049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100830.0</td>\n",
       "      <td>101218.0</td>\n",
       "      <td>101342.0</td>\n",
       "      <td>101416.0</td>\n",
       "      <td>101597.0</td>\n",
       "      <td>101936.0</td>\n",
       "      <td>102393.0</td>\n",
       "      <td>102921.0</td>\n",
       "      <td>103441.0</td>\n",
       "      <td>103889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>13414.0</td>\n",
       "      <td>14376.0</td>\n",
       "      <td>15376.0</td>\n",
       "      <td>16410.0</td>\n",
       "      <td>17470.0</td>\n",
       "      <td>18551.0</td>\n",
       "      <td>19646.0</td>\n",
       "      <td>20755.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83373.0</td>\n",
       "      <td>84878.0</td>\n",
       "      <td>85616.0</td>\n",
       "      <td>85474.0</td>\n",
       "      <td>84419.0</td>\n",
       "      <td>82326.0</td>\n",
       "      <td>79316.0</td>\n",
       "      <td>75902.0</td>\n",
       "      <td>72786.0</td>\n",
       "      <td>70473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>8994793.0</td>\n",
       "      <td>9164945.0</td>\n",
       "      <td>9343772.0</td>\n",
       "      <td>9531555.0</td>\n",
       "      <td>9728645.0</td>\n",
       "      <td>9935358.0</td>\n",
       "      <td>10148841.0</td>\n",
       "      <td>10368600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25183615.0</td>\n",
       "      <td>25877544.0</td>\n",
       "      <td>26528741.0</td>\n",
       "      <td>27207291.0</td>\n",
       "      <td>27962207.0</td>\n",
       "      <td>28809167.0</td>\n",
       "      <td>29726803.0</td>\n",
       "      <td>30682500.0</td>\n",
       "      <td>31627506.0</td>\n",
       "      <td>32526562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Angola</td>\n",
       "      <td>5270844.0</td>\n",
       "      <td>5367287.0</td>\n",
       "      <td>5465905.0</td>\n",
       "      <td>5565808.0</td>\n",
       "      <td>5665701.0</td>\n",
       "      <td>5765025.0</td>\n",
       "      <td>5863568.0</td>\n",
       "      <td>5962831.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18541467.0</td>\n",
       "      <td>19183907.0</td>\n",
       "      <td>19842251.0</td>\n",
       "      <td>20520103.0</td>\n",
       "      <td>21219954.0</td>\n",
       "      <td>21942296.0</td>\n",
       "      <td>22685632.0</td>\n",
       "      <td>23448202.0</td>\n",
       "      <td>24227524.0</td>\n",
       "      <td>25021974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Albania</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>1965598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2992547.0</td>\n",
       "      <td>2970017.0</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2904780.0</td>\n",
       "      <td>2900247.0</td>\n",
       "      <td>2896652.0</td>\n",
       "      <td>2893654.0</td>\n",
       "      <td>2889167.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Country Name       1960       1961       1962       1963  \\\n",
       "0           0        Aruba    54208.0    55435.0    56226.0    56697.0   \n",
       "1           1      Andorra    13414.0    14376.0    15376.0    16410.0   \n",
       "2           2  Afghanistan  8994793.0  9164945.0  9343772.0  9531555.0   \n",
       "3           3       Angola  5270844.0  5367287.0  5465905.0  5565808.0   \n",
       "4           4      Albania  1608800.0  1659800.0  1711319.0  1762621.0   \n",
       "\n",
       "        1964       1965        1966        1967  ...        2006        2007  \\\n",
       "0    57029.0    57360.0     57712.0     58049.0  ...    100830.0    101218.0   \n",
       "1    17470.0    18551.0     19646.0     20755.0  ...     83373.0     84878.0   \n",
       "2  9728645.0  9935358.0  10148841.0  10368600.0  ...  25183615.0  25877544.0   \n",
       "3  5665701.0  5765025.0   5863568.0   5962831.0  ...  18541467.0  19183907.0   \n",
       "4  1814135.0  1864791.0   1914573.0   1965598.0  ...   2992547.0   2970017.0   \n",
       "\n",
       "         2008        2009        2010        2011        2012        2013  \\\n",
       "0    101342.0    101416.0    101597.0    101936.0    102393.0    102921.0   \n",
       "1     85616.0     85474.0     84419.0     82326.0     79316.0     75902.0   \n",
       "2  26528741.0  27207291.0  27962207.0  28809167.0  29726803.0  30682500.0   \n",
       "3  19842251.0  20520103.0  21219954.0  21942296.0  22685632.0  23448202.0   \n",
       "4   2947314.0   2927519.0   2913021.0   2904780.0   2900247.0   2896652.0   \n",
       "\n",
       "         2014        2015  \n",
       "0    103441.0    103889.0  \n",
       "1     72786.0     70473.0  \n",
       "2  31627506.0  32526562.0  \n",
       "3  24227524.0  25021974.0  \n",
       "4   2893654.0   2889167.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 269 entries, 0 to 268\n",
      "Data columns (total 58 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    269 non-null    int64  \n",
      " 1   Country Name  269 non-null    object \n",
      " 2   1960          264 non-null    float64\n",
      " 3   1961          260 non-null    float64\n",
      " 4   1962          260 non-null    float64\n",
      " 5   1963          260 non-null    float64\n",
      " 6   1964          260 non-null    float64\n",
      " 7   1965          262 non-null    float64\n",
      " 8   1966          260 non-null    float64\n",
      " 9   1967          260 non-null    float64\n",
      " 10  1968          260 non-null    float64\n",
      " 11  1969          260 non-null    float64\n",
      " 12  1970          264 non-null    float64\n",
      " 13  1971          260 non-null    float64\n",
      " 14  1972          260 non-null    float64\n",
      " 15  1973          260 non-null    float64\n",
      " 16  1974          260 non-null    float64\n",
      " 17  1975          264 non-null    float64\n",
      " 18  1976          260 non-null    float64\n",
      " 19  1977          260 non-null    float64\n",
      " 20  1978          260 non-null    float64\n",
      " 21  1979          260 non-null    float64\n",
      " 22  1980          265 non-null    float64\n",
      " 23  1981          260 non-null    float64\n",
      " 24  1982          260 non-null    float64\n",
      " 25  1983          260 non-null    float64\n",
      " 26  1984          260 non-null    float64\n",
      " 27  1985          264 non-null    float64\n",
      " 28  1986          260 non-null    float64\n",
      " 29  1987          260 non-null    float64\n",
      " 30  1988          261 non-null    float64\n",
      " 31  1989          260 non-null    float64\n",
      " 32  1990          267 non-null    float64\n",
      " 33  1991          262 non-null    float64\n",
      " 34  1992          261 non-null    float64\n",
      " 35  1993          261 non-null    float64\n",
      " 36  1994          261 non-null    float64\n",
      " 37  1995          266 non-null    float64\n",
      " 38  1996          262 non-null    float64\n",
      " 39  1997          262 non-null    float64\n",
      " 40  1998          263 non-null    float64\n",
      " 41  1999          263 non-null    float64\n",
      " 42  2000          268 non-null    float64\n",
      " 43  2001          263 non-null    float64\n",
      " 44  2002          263 non-null    float64\n",
      " 45  2003          263 non-null    float64\n",
      " 46  2004          263 non-null    float64\n",
      " 47  2005          265 non-null    float64\n",
      " 48  2006          263 non-null    float64\n",
      " 49  2007          263 non-null    float64\n",
      " 50  2008          263 non-null    float64\n",
      " 51  2009          263 non-null    float64\n",
      " 52  2010          268 non-null    float64\n",
      " 53  2011          263 non-null    float64\n",
      " 54  2012          262 non-null    float64\n",
      " 55  2013          262 non-null    float64\n",
      " 56  2014          263 non-null    float64\n",
      " 57  2015          267 non-null    float64\n",
      "dtypes: float64(56), int64(1), object(1)\n",
      "memory usage: 122.0+ KB\n"
     ]
    }
   ],
   "source": [
    "world_pop_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `'Unnamed: 0'` column is 0-index instead of 1-indexed...this is why it's helpful to take a peek at the dataframe itself!\n",
    "\n",
    "Ok, looks like the world population data is something we could use along with the bands data. Let's see if we can make a column called `'country_population'` in the bands DataFrame that has the population of the country for that band. \n",
    "\n",
    "Let's make sure first that we actually have population data for all the countries in our bands DataFrame. We'll use the function `isin()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "International    170\n",
       "Unknown           12\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_country = bands_df['country'].isin(world_pop_df['Country Name'])\n",
    "country_not_found = bands_df['country'][~has_country]\n",
    "country_not_found.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to make sure to skip any rows that say \"International\" or \"Unknown\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple different ways to add a column. If we had the data for the column as a list, we could do it like this:\n",
    "\n",
    "`bands_df[\"country_population\"] = [283464, 1283389, ...]`\n",
    "\n",
    "Or if we wanted to put this information at a particular spot in the DataFrame, we could use the `insert()` function:\n",
    "\n",
    "`bands_df.insert(3, \"country_population\", [452342, 15425324, ...])`\n",
    "\n",
    "However, our best option will be the `assign()` function, because this provides a place for us to specify how to fill up the column:\n",
    "\n",
    "`bands_df = bands_df.assign(country_population = np.random.randint(10))`\n",
    "\n",
    "Actually, we're combining information from 2 different DataFrames, so we might actually be best off to use `merge()`, `join()`, or `concat()`. \n",
    "\n",
    "https://realpython.com/pandas-merge-join-and-concat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_df.assign(country_population = )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING SECTION\n",
    "\n",
    "Goal is to figure out the country names in world_pop_df and the country names in metal_bands_df\n",
    "\n",
    "Or was it the country names in band_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Aruba\n",
       "1            Andorra\n",
       "2        Afghanistan\n",
       "3             Angola\n",
       "4            Albania\n",
       "           ...      \n",
       "264           Taiwan\n",
       "265         Guernsey\n",
       "266          Reunion\n",
       "267    Åland Islands\n",
       "268           Jersey\n",
       "Name: Country Name, Length: 269, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_pop_df['Country Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out how to split up the comma-separated country lists into an array (if we are using metal_bands_df)\n",
    "\n",
    "Use this:\n",
    "\n",
    "`df[['origin_1', 'origin_2']] = df.Name.str.split(expand=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USA', 'Sweden', 'Germany', 'United Kingdom', 'Finland', 'Norway',\n",
       "       'France', 'Italy', 'Canada', 'The Netherlands',\n",
       "       ...\n",
       "       'Tunisia, France', 'Greece, USA', 'Israel, Germany', 'Macedonia',\n",
       "       'Portugal, United Kingdom', 'Australia, United Kingdom',\n",
       "       'Sweden, Finland', 'Hungary, United Kingdom', 'Colombia, USA',\n",
       "       'Greenland'],\n",
       "      dtype='object', length=113)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metal_bands_df['origin'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "170\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(bands_df['country'].value_counts()['Taiwan'])\n",
    "print(bands_df['country'].value_counts()['Guernsey'])\n",
    "print(bands_df['country'].value_counts()['Jersey'])\n",
    "print(bands_df['country'].value_counts()['Åland Islands'])\n",
    "print(bands_df['country'].value_counts()['Reunion'])\n",
    "print(bands_df['country'].value_counts()['International'])\n",
    "print(bands_df['country'].value_counts()['Unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the countries of bands_df to the countries of world_pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Aruba' in world_pop_df['Country Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Arba' in world_pop_df['Country Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Russia' in world_pop_df['Country Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International not found\n",
      "Unknown not found\n"
     ]
    }
   ],
   "source": [
    "for country_name in bands_df['country'].value_counts().index:\n",
    "    if country_name not in world_pop_df['Country Name'].unique():\n",
    "        print(f\"{country_name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "International    170\n",
       "Unknown           12\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_country = bands_df['country'].isin(world_pop_df['Country Name'])\n",
    "bands_df['country'][~has_country].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we know which countries we need to hunt down! Changes to make:\n",
    "\n",
    "#### For the world_pop_df:\n",
    "\n",
    "Russian Federation -> Russia\n",
    "\n",
    "Slovak Republic -> Slovakia\n",
    "\n",
    "Venezuela, RB -> Venezuela\n",
    "\n",
    "Iran, Islamic Rep. -> Iran\n",
    "\n",
    "Brunei Darussalam -> Brunei\n",
    "\n",
    "Syrian Arab Republic -> Syria\n",
    "\n",
    "Egypt, Arab Rep. -> Egypt\n",
    "\n",
    "Kyrgyz Republic -> Kyrgyzstan\n",
    "\n",
    "Lao PDR -> Laos\n",
    "\n",
    "\n",
    "#### For the bands_df:\n",
    "\n",
    "International -> no value\n",
    "\n",
    "Unknown -> no value\n",
    "\n",
    "Korea| South -> Korea, Rep.\n",
    "\n",
    "Macedonia (FYROM) -> Macedonia, FYR\n",
    "\n",
    "Curaçao -> Curacao\n",
    "\n",
    "\n",
    "#### No world pop data:\n",
    "\n",
    "Taiwan\n",
    "\n",
    "Guernsey\n",
    "\n",
    "Reunion\n",
    "\n",
    "Åland Islands\n",
    "\n",
    "Jersey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aruba', 'Andorra', 'Afghanistan', 'Angola', 'Albania',\n",
       "       'Arab World', 'United Arab Emirates', 'Argentina', 'Armenia',\n",
       "       'American Samoa', 'Antigua and Barbuda', 'Australia', 'Austria',\n",
       "       'Azerbaijan', 'Burundi', 'Belgium', 'Benin', 'Burkina Faso',\n",
       "       'Bangladesh', 'Bulgaria', 'Bahrain', 'Bahamas, The',\n",
       "       'Bosnia and Herzegovina', 'Belarus', 'Belize', 'Bermuda',\n",
       "       'Bolivia', 'Brazil', 'Barbados', 'Brunei', 'Bhutan', 'Botswana',\n",
       "       'Central African Republic', 'Canada',\n",
       "       'Central Europe and the Baltics', 'Switzerland', 'Channel Islands',\n",
       "       'Chile', 'China', \"Cote d'Ivoire\", 'Cameroon', 'Congo, Rep.',\n",
       "       'Colombia', 'Comoros', 'Cabo Verde', 'Costa Rica',\n",
       "       'Caribbean small states', 'Cuba', 'Curacao', 'Cayman Islands',\n",
       "       'Cyprus', 'Czech Republic', 'Germany', 'Djibouti', 'Dominica',\n",
       "       'Denmark', 'Dominican Republic', 'Algeria',\n",
       "       'East Asia & Pacific (excluding high income)',\n",
       "       'Early-demographic dividend', 'East Asia & Pacific',\n",
       "       'Europe & Central Asia (excluding high income)',\n",
       "       'Europe & Central Asia', 'Ecuador', 'Egypt', 'Euro area',\n",
       "       'Eritrea', 'Spain', 'Estonia', 'Ethiopia', 'European Union',\n",
       "       'Fragile and conflict affected situations', 'Finland', 'Fiji',\n",
       "       'France', 'Faroe Islands', 'Micronesia, Fed. Sts.', 'Gabon',\n",
       "       'United Kingdom', 'Georgia', 'Ghana', 'Gibraltar', 'Guinea',\n",
       "       'Gambia, The', 'Guinea-Bissau', 'Equatorial Guinea', 'Greece',\n",
       "       'Grenada', 'Greenland', 'Guatemala', 'Guam', 'Guyana',\n",
       "       'High income', 'Hong Kong SAR, China', 'Honduras',\n",
       "       'Heavily indebted poor countries (HIPC)', 'Croatia', 'Haiti',\n",
       "       'Hungary', 'IBRD only', 'IDA & IBRD total', 'IDA total',\n",
       "       'IDA blend', 'Indonesia', 'IDA only', 'Isle of Man', 'India',\n",
       "       'Not classified', 'Ireland', 'Iran', 'Iraq', 'Iceland', 'Israel',\n",
       "       'Italy', 'Jamaica', 'Jordan', 'Japan', 'Kazakhstan', 'Kenya',\n",
       "       'Kyrgyzstan', 'Cambodia', 'Kiribati', 'St. Kitts and Nevis',\n",
       "       'Korea, Rep.', 'Kosovo', 'Kuwait',\n",
       "       'Latin America & Caribbean (excluding high income)', 'Laos',\n",
       "       'Lebanon', 'Liberia', 'Libya', 'St. Lucia',\n",
       "       'Latin America & Caribbean',\n",
       "       'Least developed countries: UN classification', 'Low income',\n",
       "       'Liechtenstein', 'Sri Lanka', 'Lower middle income',\n",
       "       'Low & middle income', 'Lesotho', 'Late-demographic dividend',\n",
       "       'Lithuania', 'Luxembourg', 'Latvia', 'Macao SAR, China',\n",
       "       'St. Martin (French part)', 'Morocco', 'Monaco', 'Moldova',\n",
       "       'Madagascar', 'Maldives', 'Middle East & North Africa', 'Mexico',\n",
       "       'Marshall Islands', 'Middle income', 'Macedonia', 'Mali', 'Malta',\n",
       "       'Myanmar', 'Middle East & North Africa (excluding high income)',\n",
       "       'Montenegro', 'Mongolia', 'Northern Mariana Islands', 'Mozambique',\n",
       "       'Mauritania', 'Mauritius', 'Malawi', 'Malaysia', 'North America',\n",
       "       'Namibia', 'New Caledonia', 'Niger', 'Nigeria', 'Nicaragua',\n",
       "       'Netherlands', 'Norway', 'Nepal', 'Nauru', 'New Zealand',\n",
       "       'OECD members', 'Oman', 'Other small states', 'Pakistan', 'Panama',\n",
       "       'Peru', 'Philippines', 'Palau', 'Papua New Guinea', 'Poland',\n",
       "       'Pre-demographic dividend', 'Puerto Rico', 'South Korea',\n",
       "       'Portugal', 'Paraguay', 'Pacific island small states',\n",
       "       'Post-demographic dividend', 'French Polynesia', 'Qatar',\n",
       "       'Romania', 'Russia', 'Rwanda', 'South Asia', 'Saudi Arabia',\n",
       "       'Sudan', 'Senegal', 'Singapore', 'Solomon Islands', 'Sierra Leone',\n",
       "       'El Salvador', 'San Marino', 'Somalia', 'Serbia',\n",
       "       'Sub-Saharan Africa (excluding high income)', 'South Sudan',\n",
       "       'Sub-Saharan Africa', 'Small states', 'Sao Tome and Principe',\n",
       "       'Suriname', 'Slovakia', 'Slovenia', 'Sweden', 'Swaziland',\n",
       "       'Sint Maarten (Dutch part)', 'Seychelles', 'Syria',\n",
       "       'Turks and Caicos Islands', 'Chad',\n",
       "       'East Asia & Pacific (IDA & IBRD countries)',\n",
       "       'Europe & Central Asia (IDA & IBRD countries)', 'Togo', 'Thailand',\n",
       "       'Tajikistan', 'Turkmenistan',\n",
       "       'Latin America & the Caribbean (IDA & IBRD countries)',\n",
       "       'Middle East & North Africa (IDA & IBRD countries)', 'Timor-Leste',\n",
       "       'Tonga', 'South Asia (IDA & IBRD)',\n",
       "       'Sub-Saharan Africa (IDA & IBRD countries)', 'Trinidad and Tobago',\n",
       "       'Tunisia', 'Turkey', 'Tuvalu', 'Tanzania', 'Uganda', 'Ukraine',\n",
       "       'Upper middle income', 'Uruguay', 'United States', 'Uzbekistan',\n",
       "       'St. Vincent and the Grenadines', 'Venezuela',\n",
       "       'British Virgin Islands', 'Virgin Islands (U.S.)', 'Vietnam',\n",
       "       'Vanuatu', 'West Bank and Gaza', 'World', 'Samoa', 'Yemen, Rep.',\n",
       "       'South Africa', 'Congo, Dem. Rep.', 'Zambia', 'Zimbabwe', 'Taiwan',\n",
       "       'Guernsey', 'Reunion', 'Åland Islands', 'Jersey'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_pop_df['Country Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how to make these changes\n",
    "\n",
    "Just change the `world_pop` database names themselves. \n",
    "\n",
    "Add rows to it as well to have data for the 5 missing places. \n",
    "\n",
    "Put in a section that discusses cleaning data by removing the 'Unknown' and 'International' rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvWZmPrMpM_z"
   },
   "source": [
    "# Column Operations\n",
    "\n",
    "\n",
    "*   Removing empty cells\n",
    "*   Accessing specific columns/cells\n",
    "*   Applying functions (non-statistical) to a column\n",
    "*   Creating a new column based on data from other columns\n",
    "*   Re-ordering data? Visualizing data? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WxkBxaIoqJX"
   },
   "source": [
    "# Summation Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DARSJ0gvpmU7"
   },
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ6i9R6DtCoU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEXRUqYxzRO4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PandasWorkshop.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
